{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터셋을 로드하고 전처리하기\n",
    "\n",
    "# torchvision.transforms.Compose를 사용하여 여러 개의 변환을 연달아 적용하는 변환 파이프라인을 생성합니다.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # PIL 이미지나 numpy 배열을 PyTorch 텐서로 변환합니다.\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 입력 텐서를 평균과 표준편차를 이용해 정규화합니다.\n",
    "])\n",
    "\n",
    "# torchvision.datasets.FashionMNIST를 사용하여 FashionMNIST 데이터셋을 로드합니다.\n",
    "# root는 데이터셋이 저장될 경로를 지정하며, train=True로 설정하면 학습 데이터셋을 로드합니다.\n",
    "# download=True로 설정하면 데이터셋이 없는 경우 인터넷에서 다운로드합니다.\n",
    "# transform에는 위에서 정의한 변환 파이프라인을 적용합니다.\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# torch.utils.data.DataLoader를 사용하여 데이터셋을 배치 단위로 로드하는 데이터 로더를 생성합니다.\n",
    "# batch_size는 한 번에 로드할 데이터 샘플의 개수를 지정합니다.\n",
    "# shuffle=True로 설정하면 데이터를 섞어서 로드하며, 학습 시 데이터의 순서를 무작위로 만듭니다.\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "         MaxPool2d-2           [-1, 16, 14, 14]               0\n",
      "            Linear-3                  [-1, 128]         401,536\n",
      "            Linear-4                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 402,986\n",
      "Trainable params: 402,986\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 1.54\n",
      "Estimated Total Size (MB): 1.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "%pip install torchsummary  # torchsummary 설치\n",
    "from torchsummary import summary  # torchsummary에서 summary 함수를 임포트\n",
    "\n",
    "# FashionNet 클래스 정의: Fashion MNIST 데이터셋에 대한 신경망 모델\n",
    "class FashionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionNet, self).__init__()\n",
    "        # Convolutional layer: 입력 채널 1개, 출력 채널 16개, 커널 크기 3x3, 스트라이드 1, 패딩 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layer: 커널 크기 2x2, 스트라이드 2, 패딩 0\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Fully connected layer 1: 입력 크기 16 * 14 * 14, 출력 크기 128\n",
    "        self.fc1 = nn.Linear(16 * 14 * 14, 128)\n",
    "        # Fully connected layer 2: 입력 크기 128, 출력 크기 10 (클래스 개수)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass 구현: Convolutional layer -> Max pooling layer -> Fully connected layers\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))  # ReLU 활성화 함수와 pooling을 연속적으로 적용\n",
    "        x = x.view(-1, 16 * 14 * 14)  # Flatten the input for the fully connected layers\n",
    "        x = nn.functional.relu(self.fc1(x))  # 첫 번째 fully connected layer에 ReLU를 적용\n",
    "        x = nn.functional.log_softmax(self.fc2(x), dim=1)  # 두 번째 fully connected layer에 log softmax를 적용하여 확률 계산\n",
    "        return x\n",
    "\n",
    "# FashionNet 모델의 인스턴스 생성\n",
    "fashion_net = FashionNet()\n",
    "\n",
    "# 모델 구조 요약 정보 출력\n",
    "summary(fashion_net, input_size=(1, 28, 28))  # 입력 이미지의 크기는 (1, 28, 28)이며, 채널은 흑백 이미지이므로 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, train_loader, test_loader, epochs=5):\n",
    "    # GPU 사용 가능 여부에 따라 장치 선택\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # 모델을 선택한 장치로 이동\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저 설정\n",
    "    criterion = torch.nn.CrossEntropyLoss()  # CrossEntropyLoss를 손실 함수로 사용\n",
    "\n",
    "    # 학습 과정에서 기록할 히스토리 딕셔너리\n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            model.train()  # 모델을 학습 모드로 설정\n",
    "            train_loss, train_correct, train_total = 0, 0, 0\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), target.to(device)  # 데이터와 타겟을 선택한 장치로 이동\n",
    "                optimizer.zero_grad()  # 그래디언트 초기화\n",
    "                output = model(data)  # 모델에 입력 데이터를 전달하여 출력 계산\n",
    "                loss = criterion(output, target)  # 손실 계산\n",
    "                loss.backward()  # 역전파 수행\n",
    "                optimizer.step()  # 옵티마이저로 모델 파라미터 업데이트\n",
    "\n",
    "                # 정확도 및 손실 기록\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                train_total += target.size(0)\n",
    "                train_correct += (predicted == target).sum().item()\n",
    "\n",
    "            # 한 에폭이 끝난 후 평균 손실과 정확도 계산\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_acc = 100. * train_correct / train_total\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "\n",
    "            # 테스트 과정에서 모델을 평가 (그래디언트 계산이 필요 없으므로 torch.no_grad() 내부에서 진행)\n",
    "            model.eval()  # 모델을 평가 모드로 설정\n",
    "            test_loss, test_correct, test_total = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    data, target = data.to(device), target.to(device)  # 데이터와 타겟을 선택한 장치로 이동\n",
    "                    output = model(data)  # 모델에 입력 데이터를 전달하여 출력 계산\n",
    "                    test_loss += criterion(output, target).item()  # 테스트 손실 계산\n",
    "                    _, predicted = torch.max(output.data, 1)\n",
    "                    test_total += target.size(0)\n",
    "                    test_correct += (predicted == target).sum().item()\n",
    "\n",
    "            # 평균 테스트 손실과 정확도 계산 및 기록\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            test_acc = 100. * test_correct / test_total\n",
    "            history['test_loss'].append(test_loss)\n",
    "            history['test_acc'].append(test_acc)\n",
    "\n",
    "            # 에폭마다 결과 출력\n",
    "            print(f'Epoch {epoch+1}/{epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    return history  # 학습 과정에서의 손실과 정확도 기록을 담은 history 딕셔너리 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FashionMNIST\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 신경망 모델 정의\n",
    "class FashionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionNet, self).__init__()\n",
    "        # 첫 번째 합성곱 레이어: 입력 채널 1개, 출력 채널 16개, 커널 크기 3x3, 패딩 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        # 풀링 레이어: 최대 풀링, 커널 크기 2x2, 스트라이드 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 두 번째 합성곱 레이어: 입력 채널 16개, 출력 채널 32개, 커널 크기 3x3, 패딩 1\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # 완전 연결 레이어 1: 입력 크기 32*7*7, 출력 크기 128\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        # 완전 연결 레이어 2: 입력 크기 128, 출력 크기 10 (클래스 개수에 맞게)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력 -> 합성곱1 -> 활성화 함수(ReLU) -> 풀링\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # 풀링 -> 합성곱2 -> 활성화 함수(ReLU) -> 풀링\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Flatten 작업\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        # Flatten된 결과 -> 완전 연결 레이어1 -> 활성화 함수(ReLU)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 완전 연결 레이어2 -> 최종 출력 (logits)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 데이터셋 및 데이터로더 준비\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# 학습용 데이터셋과 DataLoader\n",
    "train_set = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "# 테스트용 데이터셋과 DataLoader\n",
    "test_set = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "\n",
    "# 모델 생성\n",
    "model = FashionNet()\n",
    "\n",
    "# train 함수를 호출하여 신경망 모델 model을 학습시키기\n",
    "hist = train(model, train_loader, test_loader, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhist\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining did not return any history.\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# hist가 None인 경우 학습 과정에 문제가 있었음을 출력\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# 학습 결과를 시각화하는 함수 plot_results 정의\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "if hist is None:\n",
    "    print(\"Training did not return any history.\")  # hist가 None인 경우 학습 과정에 문제가 있었음을 출력\n",
    "else:\n",
    "    # 학습 결과를 시각화하는 함수 plot_results 정의\n",
    "    def plot_results(history):\n",
    "        # 그래프 크기 설정\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        # 첫 번째 subplot: 손실 그래프\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['train_loss'], label='Train Loss')  # 학습 손실 그래프\n",
    "        plt.plot(history['test_loss'], label='Test Loss')  # 테스트 손실 그래프\n",
    "        plt.xlabel('Epochs')  # x축 레이블\n",
    "        plt.ylabel('Loss')  # y축 레이블\n",
    "        plt.legend()  # 범례 표시\n",
    "\n",
    "        # 두 번째 subplot: 정확도 그래프\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['train_acc'], label='Train Accuracy')  # 학습 정확도 그래프\n",
    "        plt.plot(history['test_acc'], label='Test Accuracy')  # 테스트 정확도 그래프\n",
    "        plt.xlabel('Epochs')  # x축 레이블\n",
    "        plt.ylabel('Accuracy')  # y축 레이블\n",
    "        plt.legend()  # 범례 표시\n",
    "\n",
    "        plt.show()  # 그래프 출력\n",
    "\n",
    "    plot_results(hist)  # plot_results 함수를 호출하여 hist에 저장된 학습 결과를 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
